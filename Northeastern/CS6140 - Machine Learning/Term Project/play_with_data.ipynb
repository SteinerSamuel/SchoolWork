{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "\n",
    "import meteostat\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "path = \"transitpredictor/data\"\n",
    "\n",
    "translate_stop_ids = {\n",
    "    70001: 0,\n",
    "    70003: 1,\n",
    "    70005: 2,\n",
    "    70007: 3,\n",
    "    70009: 4,\n",
    "    70011: 5,\n",
    "    70013: 6,\n",
    "    70015: 7,\n",
    "    70017: 8,\n",
    "    70019: 9,\n",
    "    70021: 10,\n",
    "    70023: 11,\n",
    "    70025: 12,\n",
    "    70027: 13,\n",
    "    70029: 14,\n",
    "    70031: 15,\n",
    "    70279: 16,\n",
    "    70033: 17,\n",
    "    70035: 18,\n",
    "    70036: 19\n",
    "}\n",
    "\n",
    "translate_event_type = {\n",
    "    \"ARR\": \"ARR\",\n",
    "    \"DEP\": \"DEP\",\n",
    "    \"PRA\": \"ARR\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "csv_filepath = path + \"/Events_2019\"\n",
    "files = glob.iglob(os.path.join(csv_filepath, \"*.csv\"))\n",
    "\n",
    "df = pd.concat((pd.read_csv(f) for i, f in enumerate(files) if i == 0))\n",
    "df = df[(df.route_id == \"Orange\") & (df.direction_id == 1)]\n",
    "df = df.drop(columns=[\"direction_id\", \"stop_sequence\", \"vehicle_id\", \"vehicle_label\"])\n",
    "df = df.sort_values([\"service_date\",\"trip_id\", \"event_time\"])\n",
    "df[\"stop_id\"] = df[\"stop_id\"].replace(translate_stop_ids)\n",
    "df[\"event_type\"] = df[\"event_type\"].replace(translate_event_type)\n",
    "df[\"event_time\"] = df[\"event_time\"].apply(datetime.fromtimestamp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        service_date route_id           trip_id  stop_id event_type  \\\n34        2019-01-01   Orange          38939742        0        ARR   \n24        2019-01-01   Orange          38939742        0        DEP   \n7         2019-01-01   Orange          38939742        1        ARR   \n25        2019-01-01   Orange          38939742        1        DEP   \n26        2019-01-01   Orange          38939742        2        ARR   \n...              ...      ...               ...      ...        ...   \n2701761   2019-03-31   Orange  ADDED-1553786854       16        DEP   \n2701749   2019-03-31   Orange  ADDED-1553786854       17        ARR   \n2701727   2019-03-31   Orange  ADDED-1553786854       17        DEP   \n2701740   2019-03-31   Orange  ADDED-1553786854       18        ARR   \n2701730   2019-03-31   Orange  ADDED-1553786854       18        DEP   \n\n                 event_time  event_time_sec  \n34      2019-01-02 00:12:33           87153  \n24      2019-01-02 00:16:09           87369  \n7       2019-01-02 00:17:43           87463  \n25      2019-01-02 00:18:23           87503  \n26      2019-01-02 00:19:22           87562  \n...                     ...             ...  \n2701761 2019-03-31 22:23:18           80598  \n2701749 2019-03-31 22:24:18           80658  \n2701727 2019-03-31 22:26:41           80801  \n2701740 2019-03-31 22:30:12           81012  \n2701730 2019-03-31 22:31:03           81063  \n\n[469235 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>service_date</th>\n      <th>route_id</th>\n      <th>trip_id</th>\n      <th>stop_id</th>\n      <th>event_type</th>\n      <th>event_time</th>\n      <th>event_time_sec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939742</td>\n      <td>0</td>\n      <td>ARR</td>\n      <td>2019-01-02 00:12:33</td>\n      <td>87153</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939742</td>\n      <td>0</td>\n      <td>DEP</td>\n      <td>2019-01-02 00:16:09</td>\n      <td>87369</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939742</td>\n      <td>1</td>\n      <td>ARR</td>\n      <td>2019-01-02 00:17:43</td>\n      <td>87463</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939742</td>\n      <td>1</td>\n      <td>DEP</td>\n      <td>2019-01-02 00:18:23</td>\n      <td>87503</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939742</td>\n      <td>2</td>\n      <td>ARR</td>\n      <td>2019-01-02 00:19:22</td>\n      <td>87562</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2701761</th>\n      <td>2019-03-31</td>\n      <td>Orange</td>\n      <td>ADDED-1553786854</td>\n      <td>16</td>\n      <td>DEP</td>\n      <td>2019-03-31 22:23:18</td>\n      <td>80598</td>\n    </tr>\n    <tr>\n      <th>2701749</th>\n      <td>2019-03-31</td>\n      <td>Orange</td>\n      <td>ADDED-1553786854</td>\n      <td>17</td>\n      <td>ARR</td>\n      <td>2019-03-31 22:24:18</td>\n      <td>80658</td>\n    </tr>\n    <tr>\n      <th>2701727</th>\n      <td>2019-03-31</td>\n      <td>Orange</td>\n      <td>ADDED-1553786854</td>\n      <td>17</td>\n      <td>DEP</td>\n      <td>2019-03-31 22:26:41</td>\n      <td>80801</td>\n    </tr>\n    <tr>\n      <th>2701740</th>\n      <td>2019-03-31</td>\n      <td>Orange</td>\n      <td>ADDED-1553786854</td>\n      <td>18</td>\n      <td>ARR</td>\n      <td>2019-03-31 22:30:12</td>\n      <td>81012</td>\n    </tr>\n    <tr>\n      <th>2701730</th>\n      <td>2019-03-31</td>\n      <td>Orange</td>\n      <td>ADDED-1553786854</td>\n      <td>18</td>\n      <td>DEP</td>\n      <td>2019-03-31 22:31:03</td>\n      <td>81063</td>\n    </tr>\n  </tbody>\n</table>\n<p>469235 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_per_day = list(df.groupby(\"service_date\"))\n",
    "len(dfs_per_day[0][1])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0936b1a31f9420582e1952eaa8280ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "dfs_per_day = list(df.groupby(\"service_date\"))\n",
    "\n",
    "for date, d in tqdm(dfs_per_day[:1]):\n",
    "    events_by_train = list(t_events[(t_events[\"event_type\"] == \"ARR\") | (t_events[\"event_type\"] == \"DEP\")].drop_duplicates() for _, t_events in d.groupby(\"trip_id\"))\n",
    "    full_runs = list(t_events for t_events in events_by_train if len(t_events) == 39)\n",
    "    if len(full_runs) == 0:\n",
    "        print(\"Skipping \" + date)\n",
    "        continue\n",
    "    full_runs = pd.concat(full_runs)\n",
    "    tids, _ = pd.factorize(full_runs[\"trip_id\"])\n",
    "    full_runs[\"train_id\"] = tids\n",
    "\n",
    "    runs_minim = full_runs[[\"train_id\", \"stop_id\", \"event_time\", \"event_time_sec\", \"event_type\"]].groupby(\"train_id\")\n",
    "    e = []\n",
    "    for tid, r in runs_minim:\n",
    "        arrs = r[r[\"event_type\"] == \"ARR\"]\n",
    "        deps = r[r[\"event_type\"] == \"DEP\"]\n",
    "\n",
    "        event_pairs = arrs.join(deps, how=\"cross\", lsuffix=\"_arr\", rsuffix=\"_dep\")\n",
    "        event_pairs = event_pairs[event_pairs[\"stop_id_arr\"] > event_pairs[\"stop_id_dep\"]] # Sequential order\n",
    "        event_pairs[\"total_travel_time\"] = event_pairs[\"event_time_sec_arr\"] - event_pairs[\"event_time_sec_dep\"]\n",
    "        event_pairs = event_pairs[[\"train_id_arr\", \"stop_id_dep\", \"stop_id_arr\", \"total_travel_time\", \"event_time_arr\", \"event_time_sec_arr\"]]\n",
    "        event_pairs.rename(columns={\"train_id_arr\":\"train_id\"}, inplace=True)\n",
    "        event_pairs = event_pairs.sort_values([\"train_id\", \"stop_id_dep\", \"stop_id_arr\"])\n",
    "        e.append(event_pairs)\n",
    "\n",
    "    runs = full_runs\n",
    "\n",
    "    # Calculate dwell time\n",
    "    runs[[\"prev_event_type\", \"prev_stop_id\", \"prev_trip_id\", \"prev_event_time_sec\"]] = runs[[\"event_type\", \"stop_id\", \"trip_id\", \"event_time_sec\"]].shift(1)\n",
    "    runs[\"dwell_time\"] = np.where((runs[\"prev_event_type\"] == \"ARR\") & (runs[\"event_type\"] == \"DEP\") & (runs[\"prev_stop_id\"] == runs[\"stop_id\"]) & (runs[\"prev_trip_id\"] == runs[\"trip_id\"]), runs[\"event_time_sec\"] - runs[\"prev_event_time_sec\"], math.nan)\n",
    "    runs = runs.drop(columns=[\"prev_event_type\", \"prev_stop_id\", \"prev_trip_id\", \"prev_event_time_sec\"])\n",
    "\n",
    "    # We no longer care about arrivals at all\n",
    "    runs = runs[runs[\"event_type\"] == \"DEP\"]\n",
    "    runs = runs.drop(columns=[\"event_type\"])\n",
    "\n",
    "    # Pair up each train for the day with the next one that departs from the same station\n",
    "    runs = runs.sort_values([\"stop_id\", \"event_time_sec\"])\n",
    "    runs[[\"prev_stop_id\", \"prev_event_time_sec\"]] = runs[[\"stop_id\", \"event_time_sec\"]].shift(1)\n",
    "    runs[\"headway\"] = np.where(runs[\"prev_stop_id\"] == runs[\"stop_id\"], runs[\"event_time_sec\"] - runs[\"prev_event_time_sec\"], math.nan)\n",
    "    runs = runs.drop(columns=[\"prev_stop_id\", \"prev_event_time_sec\"])\n",
    "\n",
    "    forest_hills_deps = runs[runs[\"stop_id\"] == 0].drop(columns=[\"stop_id\", \"route_id\", \"dwell_time\", \"event_time\", \"service_date\", \"trip_id\", \"headway\"]).reindex(columns=[\"train_id\", \"event_time_sec\"])\n",
    "    runs = runs.merge(forest_hills_deps, left_on=\"train_id\", right_on=\"train_id\", how=\"inner\", suffixes=(\"\", \"_fh_dep\"))\n",
    "    runs[\"train_timestamp\"] = runs[\"event_time_sec\"] - runs[\"event_time_sec_fh_dep\"]\n",
    "    runs = runs.drop(columns=\"event_time_sec_fh_dep\")\n",
    "\n",
    "    runs = runs.sort_values([\"event_time_sec\"])\n",
    "\n",
    "    # all_trains_day = pd.concat(e)\n",
    "    results[datetime.strptime(date, \"%Y-%m-%d\")] = runs, pd.concat(e)\n",
    "\n",
    "# make dict a Dataframe to save to csv\n",
    "# results = pd.concat(results)\n",
    "# results.index.names = [\"service_date\", \"cut_index\"]\n",
    "# results = results.reset_index(level=\"cut_index\").drop(columns=[\"cut_index\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "     service_date route_id   trip_id  stop_id          event_time  \\\n0      2019-01-01   Orange  38939782        0 2019-01-01 06:00:26   \n1      2019-01-01   Orange  38939782        1 2019-01-01 06:02:47   \n2      2019-01-01   Orange  38939782        2 2019-01-01 06:04:28   \n3      2019-01-01   Orange  38939782        3 2019-01-01 06:06:26   \n4      2019-01-01   Orange  38939782        4 2019-01-01 06:08:06   \n...           ...      ...       ...      ...                 ...   \n1667   2019-01-01   Orange  38939743       14 2019-01-02 01:24:35   \n1668   2019-01-01   Orange  38939743       15 2019-01-02 01:26:43   \n1669   2019-01-01   Orange  38939743       16 2019-01-02 01:28:43   \n1670   2019-01-01   Orange  38939743       17 2019-01-02 01:30:21   \n1671   2019-01-01   Orange  38939743       18 2019-01-02 01:34:30   \n\n      event_time_sec  train_id  dwell_time  headway  train_timestamp  \n0              21626        13       466.0      NaN                0  \n1              21767        13        42.0      NaN              141  \n2              21868        13        39.0      NaN              242  \n3              21986        13        48.0      NaN              360  \n4              22086        13        48.0      NaN              460  \n...              ...       ...         ...      ...              ...  \n1667           91475         0        54.0   3522.0             3177  \n1668           91603         0        46.0   3462.0             3305  \n1669           91723         0        49.0   3445.0             3425  \n1670           91821         0        43.0   3419.0             3523  \n1671           92070         0        58.0   3393.0             3772  \n\n[1672 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>service_date</th>\n      <th>route_id</th>\n      <th>trip_id</th>\n      <th>stop_id</th>\n      <th>event_time</th>\n      <th>event_time_sec</th>\n      <th>train_id</th>\n      <th>dwell_time</th>\n      <th>headway</th>\n      <th>train_timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939782</td>\n      <td>0</td>\n      <td>2019-01-01 06:00:26</td>\n      <td>21626</td>\n      <td>13</td>\n      <td>466.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939782</td>\n      <td>1</td>\n      <td>2019-01-01 06:02:47</td>\n      <td>21767</td>\n      <td>13</td>\n      <td>42.0</td>\n      <td>NaN</td>\n      <td>141</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939782</td>\n      <td>2</td>\n      <td>2019-01-01 06:04:28</td>\n      <td>21868</td>\n      <td>13</td>\n      <td>39.0</td>\n      <td>NaN</td>\n      <td>242</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939782</td>\n      <td>3</td>\n      <td>2019-01-01 06:06:26</td>\n      <td>21986</td>\n      <td>13</td>\n      <td>48.0</td>\n      <td>NaN</td>\n      <td>360</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939782</td>\n      <td>4</td>\n      <td>2019-01-01 06:08:06</td>\n      <td>22086</td>\n      <td>13</td>\n      <td>48.0</td>\n      <td>NaN</td>\n      <td>460</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1667</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939743</td>\n      <td>14</td>\n      <td>2019-01-02 01:24:35</td>\n      <td>91475</td>\n      <td>0</td>\n      <td>54.0</td>\n      <td>3522.0</td>\n      <td>3177</td>\n    </tr>\n    <tr>\n      <th>1668</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939743</td>\n      <td>15</td>\n      <td>2019-01-02 01:26:43</td>\n      <td>91603</td>\n      <td>0</td>\n      <td>46.0</td>\n      <td>3462.0</td>\n      <td>3305</td>\n    </tr>\n    <tr>\n      <th>1669</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939743</td>\n      <td>16</td>\n      <td>2019-01-02 01:28:43</td>\n      <td>91723</td>\n      <td>0</td>\n      <td>49.0</td>\n      <td>3445.0</td>\n      <td>3425</td>\n    </tr>\n    <tr>\n      <th>1670</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939743</td>\n      <td>17</td>\n      <td>2019-01-02 01:30:21</td>\n      <td>91821</td>\n      <td>0</td>\n      <td>43.0</td>\n      <td>3419.0</td>\n      <td>3523</td>\n    </tr>\n    <tr>\n      <th>1671</th>\n      <td>2019-01-01</td>\n      <td>Orange</td>\n      <td>38939743</td>\n      <td>18</td>\n      <td>2019-01-02 01:34:30</td>\n      <td>92070</td>\n      <td>0</td>\n      <td>58.0</td>\n      <td>3393.0</td>\n      <td>3772</td>\n    </tr>\n  </tbody>\n</table>\n<p>1672 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = results.values().__iter__().__next__()[0]#.reindex(columns=[\"train_id\", \"service_date\", \"stop_id\", \"route_id\", \"dwell_time\", \"trip_id\", \"headway\", \"event_time\", \"event_time_sec\"])\n",
    "\n",
    "runs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}