# CS6120-HW2
In this repository, there are two Jupyter notebooks, each of which contains two tasks and their relevant instructions. We'll work with character-level language models so that training is fast and doesn't take too much memory.

Start with LanguageModeling.ipynb, which walks through building character-level n-gram models.

Then work on SequencePrediction.ipynb, which walks through modifying and evaluating character-level recurrent neural network models.

## Assignment Instructions:
1. Update this README to include your names before submission.
2. SequencePrediction.ipynb can make use of CUDA capabilities to run the code on a GPU. If you are using Google Colab, turning on the GPU will speed-up runtime.
3. To save your work directly from Google Colab, follow these instructions:
    - Open Google Colab
    - To load the notebook, go to the GitHub tab
    - Authorize Colab access to your repositories (check 'Include private repos')
    - Use "Save a copy to GitHub"
